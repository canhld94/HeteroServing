{
  "ip": "0.0.0.0",
  "port": "8081",
  "inference engines": [
    {
      "device": "cpu",
      "models": []
    },
    {
      "device": "fpga",
      "models": [
        {
          "name": "yolov3",
          "graph": "/home/canhld/workplace/InferenceServer/openvino_models/dota/yolo_v3_dota_fp16.xml",
          "label": "/home/canhld/workplace/InferenceServer/openvino_models/dota/dota_yolo.txt",
          "replicas": "1"
        }
      ],
      "bitstream": "/opt/intel/openvino_2019.1.144/bitstreams/a10_devkit_bitstreams/2019R1_A10DK_FP16_MobileNet_Clamp.aocx"
    },
    {
      "device": "gpu",
      "models": []
    }
  ]
}
