{
    "ip": "0.0.0.0",
    "port": "8081",
    "inference engines": [
      {
        "name": "rcnn",
        "device": "fpga",
        "model": "/home/canhld/workplace/InferenceServer/openvino_models/faster_rcnn_fp32.xml",
        "labels": "/home/canhld/workplace/InferenceServer/openvino_models/ms_coco_91.txt",
        "fpga configuration": {
          "dev": "acla0",
          "bitstream": "/opt/intel/openvino_2019.1.144/bitstreams/a10_devkit_bitstreams/2019R1_A10DK_FP16_MobileNet_Clamp.aocx"
        }
      },
      {
        "name": "rcnn",
        "device": "cpu",
        "model": "/home/canhld/workplace/InferenceServer/openvino_models/faster_rcnn_fp32.xml",
        "labels": "/home/canhld/workplace/InferenceServer/openvino_models/ms_coco_91.txt"
      },
      {
        "name": "rcnn",
        "device": "cpu",
        "model": "/home/canhld/workplace/InferenceServer/openvino_models/faster_rcnn_fp32.xml",
        "labels": "/home/canhld/workplace/InferenceServer/openvino_models/ms_coco_91.txt"
      },      {
        "name": "rcnn",
        "device": "cpu",
        "model": "/home/canhld/workplace/InferenceServer/openvino_models/faster_rcnn_fp32.xml",
        "labels": "/home/canhld/workplace/InferenceServer/openvino_models/ms_coco_91.txt"
      },
      {
        "name": "rcnn",
        "device": "cpu",
        "model": "/home/canhld/workplace/InferenceServer/openvino_models/faster_rcnn_fp32.xml",
        "labels": "/home/canhld/workplace/InferenceServer/openvino_models/ms_coco_91.txt"
      }
    ]
  }
  